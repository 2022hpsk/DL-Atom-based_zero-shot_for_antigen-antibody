

# ReadMe

[TOC]
### Setup

####  1、Environment

We have provided the `env.yml` for creating the runtime conda environment just by running:

```python
conda env create -f env.yml
conda activate AAZA
```

```
conda install pyg -c pyg
```

```
pip install torch_scatter
```

```
pip install torch_sparse
```

If there is something wrong, maybe your Cuda version is not  suitable

####  2、PDB data

Please download all the structure data of antibodies from the [download page of SAbDab](http://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/search/?all=true). Please enter the *Downloads* tab on the left of the web page and download the archived zip file for the structures, then decompress it:

```
wget https://opig.stats.ox.ac.uk/webapps/newsabdab/sabdab/archive/all/ -O all_structures.zip
unzip all_structures.zip
```

You should get a folder named *all_structures* with the following hierarchy:

```
├── all_structures
│   ├── chothia
│   ├── imgt
│   ├── raw
```

Each subfolder contains the pdb files renumbered with the corresponding scheme. We use IMGT in the paper, so the imgt subfolder is what we care about.


NOTE: Our folder contains the All_Data folder generated by our pre -processing process, which contains the absolute path of our data, so it cannot be used directly, you need to delete it and pre-process it yourself to generate the all_data folder.

### Data Preprocessing

**Data**

To preprocess the raw data, we need to first generate summaries for each benchmark in json format, then split the datasets into train/validation/test sets, and finally transform the pdb data to python objects. We have provided the script for all these procedures in `scripts/data_preprocess.sh`. Suppose the IMGT-renumbered pdb data are located at `all_structures/imgt/`, and that you want to store the processed data (~5G) at `all_data`, you can simply run:

```
bash scripts/data_preprocess.sh all_structures/imgt all_data
```

which takes about 1 hour to process SAbDab, RAbD, Igfold test set, and SKEMPI V2.0. It is normal to see reported errors in this process because some antibody structures are wrongly annotated or have wrong format, which will be dropped out in the data cleaning phase.



### Train

We just run the train process at RAbD set, use the command:

```
python fold.py 
```

If you want to run on the remote server without being stopped, due to the unexpected connection loss ,use the following command:

```
nohup python -u fold.py & 
```

 





